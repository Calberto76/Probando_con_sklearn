{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise M3.01\n",
        "\n",
        "The goal is to write an exhaustive search to find the best parameters combination maximizing the model generalization performance.\n",
        "\n",
        "Here we use a small subset of the Adult Census dataset to make the code faster to execute. Once your code works on the small subset, try to change train_size to a larger value (e.g. 0.8 for 80% instead of 20%)."
      ],
      "metadata": {
        "id": "SjgZz7aWxDT8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GG5Ph0FGxBRF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "adult_census = pd.read_csv(\"/content/drive/MyDrive/DataSets/Adult_Census/adult-census(1).csv\")\n",
        "\n",
        "target_name = \"class\"\n",
        "target = adult_census[target_name]\n",
        "data = adult_census.drop(columns=[target_name, \"education-num\"])\n",
        "\n",
        "data_train, data_test, target_train, target_test = train_test_split(\n",
        "    data, target, train_size=0.8, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "xys8isPUxLxh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_preprocessor = OrdinalEncoder(\n",
        "    handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
        ")\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        (\n",
        "            \"cat_preprocessor\",\n",
        "            categorical_preprocessor,\n",
        "            selector(dtype_include=object),\n",
        "        )\n",
        "    ],\n",
        "    remainder=\"passthrough\",\n",
        ")\n",
        "\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model = Pipeline(\n",
        "    [\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", HistGradientBoostingClassifier(random_state=42)),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "kk8iPTDlxMP3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the previously defined model (called model) and using two nested for loops, make a search of the best combinations of the learning_rate and max_leaf_nodes parameters. In this regard, you have to train and test the model by setting the parameters. The evaluation of the model should be performed using cross_val_score on the training set. Use the following parameters search:\n",
        "\n",
        "    learning_rate for the values 0.01, 0.1, 1 and 10. This parameter controls the ability of a new tree to correct the error of the previous sequence of trees\n",
        "    max_leaf_nodes for the values 3, 10, 30. This parameter controls the depth of each tree.\n",
        "\n"
      ],
      "metadata": {
        "id": "gVRkUq9pxwmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.01, 0.1, 1, 10]\n",
        "max_leaf_nodes_values = [3, 10, 30]\n",
        "\n",
        "best_score = 0\n",
        "best_params = {}\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    for max_leaf_nodes in max_leaf_nodes_values:\n",
        "\n",
        "        model.set_params(classifier__learning_rate=learning_rate,\n",
        "                         classifier__max_leaf_nodes=max_leaf_nodes)\n",
        "\n",
        "\n",
        "        scores = cross_val_score(model, data_train, target_train, cv=5)\n",
        "\n",
        "\n",
        "        mean_score = scores.mean()\n",
        "\n",
        "\n",
        "        if mean_score > best_score:\n",
        "            best_score = mean_score\n",
        "            best_params = {'learning_rate': learning_rate, 'max_leaf_nodes': max_leaf_nodes}\n",
        "\n",
        "# Print the best score and the corresponding parameters\n",
        "print(f\"Best score: {best_score}\")\n",
        "print(f\"Best parameters: {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNUK9ZlZxuwr",
        "outputId": "9c37624e-f546-4e82-b469-bda0688fe73f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score: 0.8714456736526677\n",
            "Best parameters: {'learning_rate': 0.1, 'max_leaf_nodes': 30}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use the test set to score the model using the best parameters that we found using cross-validation. You will have to refit the model over the full training set."
      ],
      "metadata": {
        "id": "TCu0ulvqyDel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.set_params(classifier__learning_rate=best_params['learning_rate'],\n",
        "                 classifier__max_leaf_nodes=best_params['max_leaf_nodes'])\n",
        "\n",
        "model.fit(data_train, target_train)\n",
        "\n",
        "test_score = model.score(data_test, target_test)\n",
        "\n",
        "print(f\"Test score: {test_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb9orCdpyD-b",
        "outputId": "106893e8-22b2-4ea8-81af-4ef24b9df8b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.8789026512437301\n"
          ]
        }
      ]
    }
  ]
}