{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise M3.02\n",
        "\n",
        "The goal is to find the best set of hyperparameters which maximize the generalization performance on a training set.\n"
      ],
      "metadata": {
        "id": "rjfSGcAD7PzP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y_RdHDIO7Llz"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
        "target *= 100  # rescale the target in k$\n",
        "\n",
        "data_train, data_test, target_train, target_test = train_test_split(\n",
        "    data, target, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "EBmZm1Vd7Taf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, we progressively define the regression pipeline and later tune its hyperparameters.\n",
        "\n",
        "Start by defining a pipeline that:\n",
        "\n",
        "    uses a StandardScaler to normalize the numerical data;\n",
        "    uses a sklearn.neighbors.KNeighborsRegressor as a predictive model.\n",
        "\n"
      ],
      "metadata": {
        "id": "HQlgqQlY7qTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([('scaler', StandardScaler()),\n",
        "                     ('knn', KNeighborsRegressor())])\n",
        "pipeline.fit(data_train, target_train)\n",
        "predictions = pipeline.predict(data_test)"
      ],
      "metadata": {
        "id": "c8bG9lef7qvK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use RandomizedSearchCV with n_iter=20 to find the best set of hyperparameters by tuning the following parameters of the model:\n",
        "\n",
        "    the parameter n_neighbors of the KNeighborsRegressor with values np.logspace(0, 3, num=10).astype(np.int32);\n",
        "    the parameter with_mean of the StandardScaler with possible values True or False;\n",
        "    the parameter with_std of the StandardScaler with possible values True or False.\n",
        "\n",
        "Notice that in the notebook \"Hyperparameter tuning by randomized-search\" we pass distributions to be sampled by the RandomizedSearchCV. In this case we define a fixed grid of hyperparameters to be explored. Using a GridSearchCV instead would explore all the possible combinations on the grid, which can be costly to compute for large grids, whereas the parameter n_iter of the RandomizedSearchCV controls the number of different random combination that are evaluated. Notice that setting n_iter larger than the number of possible combinations in a grid (in this case 10 x 2 x 2 = 40) would lead to repeating already-explored combinations.\n",
        "\n",
        "Once the computation has completed, print the best combination of parameters stored in the best_params_ attribute.\n"
      ],
      "metadata": {
        "id": "nHjtAm8s7zhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_distributions = {\n",
        "    'scaler__with_mean': [True, False],\n",
        "    'scaler__with_std': [True, False],\n",
        "    'knn__n_neighbors': np.logspace(0, 3, num=10).astype(np.int32)\n",
        "}\n",
        "\n",
        "# Set up the randomized search with n_iter=20\n",
        "random_search = RandomizedSearchCV(\n",
        "    pipeline, param_distributions=param_distributions, n_iter=20, random_state=42\n",
        ")\n",
        "\n",
        "# Fit the randomized search to find the best hyperparameters\n",
        "random_search.fit(data_train, target_train)\n",
        "\n",
        "# Print the best combination of parameters\n",
        "print(\"Best hyperparameters:\", random_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6meYQh6g7z_3",
        "outputId": "f41a5591-aaee-4c8d-8676-c6a831b58091"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'scaler__with_std': True, 'scaler__with_mean': True, 'knn__n_neighbors': 10}\n"
          ]
        }
      ]
    }
  ]
}