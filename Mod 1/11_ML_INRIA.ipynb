{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise M1.05\n",
        "\n",
        "The goal of this exercise is to evaluate the impact of feature preprocessing on a pipeline that uses a decision-tree-based classifier instead of a logistic regression.\n",
        "\n",
        "    The first question is to empirically evaluate whether scaling numerical features is helpful or not;\n",
        "    The second question is to evaluate whether it is empirically better (both from a computational and a statistical perspective) to use integer coded or one-hot encoded categories.\n"
      ],
      "metadata": {
        "id": "0YXtfJ8nv3jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier"
      ],
      "metadata": {
        "id": "Yoy8Pmh2v6CG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_census = pd.read_csv(\"/content/drive/MyDrive/DataSets/Adult_Census/adult-census(1).csv\")\n"
      ],
      "metadata": {
        "id": "2d-1W9p6v_tk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_name = \"class\"\n",
        "target = adult_census[target_name]\n",
        "data = adult_census.drop(columns=[target_name, \"education-num\"])"
      ],
      "metadata": {
        "id": "vxdxnjSAwM0s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in the previous notebooks, we use the utility make_column_selector to select only columns with a specific data type. Besides, we list in advance all categories for the categorical columns.\n"
      ],
      "metadata": {
        "id": "flHnshnMwnSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns_selector = selector(dtype_exclude=object)\n",
        "categorical_columns_selector = selector(dtype_include=object)\n",
        "numerical_columns = numerical_columns_selector(data)\n",
        "categorical_columns = categorical_columns_selector(data)"
      ],
      "metadata": {
        "id": "CtvAtWEzwOZ9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference pipeline (no numerical scaling and integer-coded categories)\n",
        "\n",
        "First let's time the pipeline we used in the main notebook to serve as a reference:\n"
      ],
      "metadata": {
        "id": "3ViZWAjrwxW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_preprocessor = OrdinalEncoder(\n",
        "    handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
        ")\n",
        "preprocessor = ColumnTransformer(\n",
        "    [(\"categorical\", categorical_preprocessor, categorical_columns)],\n",
        "    remainder=\"passthrough\",\n",
        ")\n",
        "\n",
        "model = make_pipeline(preprocessor, HistGradientBoostingClassifier())\n",
        "\n",
        "start = time.time()\n",
        "cv_results = cross_validate(model, data, target)\n",
        "elapsed_time = time.time() - start\n",
        "\n",
        "scores = cv_results[\"test_score\"]\n",
        "\n",
        "print(\n",
        "    \"The mean cross-validation accuracy is: \"\n",
        "    f\"{scores.mean():.3f} ± {scores.std():.3f} \"\n",
        "    f\"with a fitting time of {elapsed_time:.3f}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjYArNIyxB-S",
        "outputId": "b61aef66-62c8-4b09-b498-86e8cd1c0bb6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean cross-validation accuracy is: 0.874 ± 0.002 with a fitting time of 5.010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling numerical features\n",
        "\n",
        "Let's write a similar pipeline that also scales the numerical features using StandardScaler (or similar):\n"
      ],
      "metadata": {
        "id": "F8Kvf-R5xHrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_preprocesor = StandardScaler()\n",
        "preprocesor_SS = ColumnTransformer([\n",
        "    (\"numerical\", numerical_preprocesor, numerical_columns)])\n",
        "\n",
        "model_SS =make_pipeline(preprocesor_SS, HistGradientBoostingClassifier())\n",
        "\n",
        "start = time.time()\n",
        "cv_results_SS = cross_validate(model_SS, data, target)\n",
        "elapsed_time = time.time() - start\n",
        "\n",
        "scores_SS = cv_results_SS[\"test_score\"]\n",
        "\n",
        "print(\n",
        "    \"The mean cross-validation accuracy is: \"\n",
        "    f\"{scores_SS.mean():.3f} ± {scores_SS.std():.3f} \"\n",
        "    f\"with a fitting time of {elapsed_time:.3f}\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXepcF9HxI5N",
        "outputId": "8c2f6374-d22e-4db6-bfba-8a769830b500"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean cross-validation accuracy is: 0.831 ± 0.001 with a fitting time of 3.129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot encoding of categorical variables\n",
        "\n",
        "We observed that integer coding of categorical variables can be very\n",
        "detrimental for linear models. However, it does not seem to be the case for\n",
        "`HistGradientBoostingClassifier` models, as the cross-validation score of the\n",
        "reference pipeline with `OrdinalEncoder` is reasonably good.\n",
        "\n",
        "Let's see if we can get an even better accuracy with `OneHotEncoder`.\n",
        "\n",
        "Hint: `HistGradientBoostingClassifier` does not yet support sparse input data.\n",
        "You might want to use `OneHotEncoder(handle_unknown=\"ignore\",\n",
        "sparse_output=False)` to force the use of a dense representation as a\n",
        "workaround."
      ],
      "metadata": {
        "id": "ygsmfGgDxTE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_preprocessor_OHE = OneHotEncoder(\n",
        "    handle_unknown=\"ignore\", sparse_output = False\n",
        ")\n",
        "\n",
        "preprocessor_OHE = ColumnTransformer(\n",
        "    [(\"categorical\", categorical_preprocessor_OHE, categorical_columns)],\n",
        "    remainder=\"passthrough\",\n",
        ")\n",
        "\n",
        "model_OHE = make_pipeline(preprocessor_OHE, HistGradientBoostingClassifier())\n",
        "\n",
        "start = time.time()\n",
        "cv_results_OHE = cross_validate(model_OHE, data, target)\n",
        "elapsed_time = time.time() - start\n",
        "\n",
        "scores_OHE = cv_results_OHE[\"test_score\"]\n",
        "\n",
        "print(\n",
        "    \"The mean cross-validation accuracy is: \"\n",
        "    f\"{scores_OHE.mean():.3f} ± {scores_OHE.std():.3f} \"\n",
        "    f\"with a fitting time of {elapsed_time:.3f}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdTrCxQCxUEA",
        "outputId": "6a350cfc-32d8-46e6-93b5-ddfc38821440"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean cross-validation accuracy is: 0.874 ± 0.002 with a fitting time of 15.527\n"
          ]
        }
      ]
    }
  ]
}